{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from scipy.spatial.transform import Rotation\n",
    "import unittest\n",
    "import importlib  \n",
    "\n",
    "gvp = importlib.import_module(\"gvp-pytorch.gvp\")\n",
    "gvp.models = importlib.import_module(\"gvp-pytorch.gvp.models\")\n",
    "gvp.data = importlib.import_module(\"gvp-pytorch.gvp.data\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Equivariance: Robustness in Protein Models\n",
    "\n",
    "Equivariance is the consistency of a model's output with regard to particular input transformations. When the output is unaffected by changes made to the input, a model is said to be equivariant. For example, in computer vision tasks, an equivariant model will produce consistent predictions regardless of the translation, rotation, or scaling applied to the input image. Verifying and quantifying equivariance to rotations is crucial to establish the reliability and robustness of models that analyze protein structures.\n",
    "\n",
    "In this demo, we investigate the equivariance to rotations of the GVP and our implementation of the steerable MLP. Our objective is to evaluate the robustness and consistency of the models' output when subjected to rotations.\n",
    "\n",
    "To do so, we first create random `300` random nodes, with each node having `16` vector features. Then, we define a class that has tests for the GVP, GVP with vector gating and our steerable MLP implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_dim = (100, 16)\n",
    "n_nodes = 300\n",
    "nodes = gvp.randn(n_nodes, node_dim, device=device)\n",
    "\n",
    "class EquivarianceTest(unittest.TestCase):\n",
    "\n",
    "    \"\"\"\n",
    "    This is a class that tests whether the GVP with and without vector gating is \n",
    "    equivariant to rotation.\n",
    "    \n",
    "    First, the test_equivariance function is called where all the\n",
    "    features are rotated using the same rotation matrix.\n",
    "\n",
    "    Second, the test_equivariance_per_feature is called, where every\n",
    "    feature is rotated where each feature is rotated with a different\n",
    "    rotation matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    def test_gvp(self):\n",
    "        model = gvp.GVP(node_dim, node_dim).to(device).eval()\n",
    "        model_fn = lambda h_V: model(h_V)\n",
    "        test_equivariance(model_fn, nodes)\n",
    "        \n",
    "        \n",
    "    def test_gvp_vector_gate(self):\n",
    "        model = gvp.GVP(node_dim, node_dim, vector_gate=True).to(device).eval()\n",
    "        model_fn = lambda h_V: model(h_V)\n",
    "        test_equivariance(model_fn, nodes)\n",
    "\n",
    "    def test_steerable_MLP(self):\n",
    "        return\n",
    "        model # =  TODO\n",
    "        model_fn = lambda h_V: model(h_V)\n",
    "        test_equivariance(model_fn, nodes)\n",
    "\n",
    "    # I think this does not hold; test doesn't pass.\n",
    "    def test_gvp_per_feature(self):\n",
    "        model = gvp.GVP(node_dim, node_dim).to(device).eval()\n",
    "        model_fn = lambda h_V: model(h_V)\n",
    "        test_equivariance_per_feature(model_fn, nodes)\n",
    "    def test_gvp_vector_gate_per_feature(self):\n",
    "        model = gvp.GVP(node_dim, node_dim, vector_gate=True).to(device).eval()\n",
    "        model_fn = lambda h_V: model(h_V)\n",
    "        test_equivariance_per_feature(model_fn, nodes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's enhance the clarity of the tests regarding our desired objectives. Our aim is to ensure that the scalar output features of the model remain unchanged under rotation, as scalars possess inherent rotation invariance. Additionally, we expect the vector features to exhibit rotation equivariance, implying that the model's output, after rotating the original vector input, should be identical to rotating the output obtained by passing the original vector input through the model. Or also in another representation:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\text{Invariance:}   && \\text{model}(\\text{rotation}(\\text{scalars})) &= \\text{model}(\\text{scalars})         \\\\\n",
    "\\text{Equivariance:} && \\text{model}(\\text{rotation}(\\text{vectors})) &= \\text{rotation}(\\text{model}(\\text{vectors})).\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_equivariance(model, nodes):\n",
    "    \n",
    "    random = torch.as_tensor(Rotation.random().as_matrix(), \n",
    "                             dtype=torch.float32, device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        out_s, out_v = model(nodes)\n",
    "        n_v_rot = nodes[1] @ random\n",
    "        out_v_rot = out_v @ random\n",
    "        out_s_prime, out_v_prime = model((nodes[0], n_v_rot))\n",
    "        \n",
    "        assert torch.allclose(out_s, out_s_prime, atol=1e-5, rtol=1e-4)\n",
    "        assert torch.allclose(out_v_rot, out_v_prime, atol=1e-5, rtol=1e-4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an attempt to rotate a single vector feature and see if this gives an equivariant result. However, this is unsuccessful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_equivariance_per_feature(model, nodes):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for feature in range(nodes[1].shape[1]):\n",
    "            random = torch.as_tensor(Rotation.random().as_matrix(), \n",
    "                             dtype=torch.float32, device=device)\n",
    "    \n",
    "            out_s, out_v = model(nodes)\n",
    "\n",
    "            # rotate a single input vector feature\n",
    "            n_v_rot = nodes[1][:, feature, :] @ random\n",
    "            # rotate a single output vector feature\n",
    "            out_v_rot = out_v[:, feature, :] @ random\n",
    "\n",
    "            # concatenate the features back together\n",
    "            full_n_v_rot = torch.cat((nodes[1][:, :feature, :], n_v_rot.unsqueeze(1), nodes[1][:, feature+1:, :]), 1)\n",
    "            full_out_v_rot = torch.cat((out_v[:, :feature, :], out_v_rot.unsqueeze(1), out_v[:, feature+1:, :]), 1)\n",
    "\n",
    "            out_s_prime, out_v_prime = model((nodes[0], full_n_v_rot))\n",
    "            \n",
    "            assert torch.allclose(out_s, out_s_prime, atol=1e-5, rtol=1e-4)\n",
    "            assert torch.allclose(full_out_v_rot, out_v_prime, atol=1e-5, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".F.F.\n",
      "======================================================================\n",
      "FAIL: test_gvp_per_feature (__main__.EquivarianceTest.test_gvp_per_feature)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_44923/1428190658.py\", line 40, in test_gvp_per_feature\n",
      "    test_equivariance_per_feature(model_fn, nodes)\n",
      "  File \"/tmp/ipykernel_44923/2527260079.py\", line 21, in test_equivariance_per_feature\n",
      "    assert torch.allclose(out_s, out_s_prime, atol=1e-5, rtol=1e-4)\n",
      "AssertionError\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_gvp_vector_gate_per_feature (__main__.EquivarianceTest.test_gvp_vector_gate_per_feature)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_44923/1428190658.py\", line 44, in test_gvp_vector_gate_per_feature\n",
      "    test_equivariance_per_feature(model_fn, nodes)\n",
      "  File \"/tmp/ipykernel_44923/2527260079.py\", line 21, in test_equivariance_per_feature\n",
      "    assert torch.allclose(out_s, out_s_prime, atol=1e-5, rtol=1e-4)\n",
      "AssertionError\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.020s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
