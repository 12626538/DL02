{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.transforms import Distance\n",
    "import torch_geometric as tg\n",
    "import torch_geometric.data.batch as tg_batch\n",
    "\n",
    "from torch_cluster import radius_graph\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import atom3dutils\n",
    "\n",
    "from e3nn import o3\n",
    "from e3nn.o3 import Irreps\n",
    "from e3nn.nn import Gate\n",
    "\n",
    "from scipy.spatial.transform import Rotation\n",
    "import unittest\n",
    "import importlib  \n",
    "\n",
    "gvp = importlib.import_module(\"gvp-pytorch.gvp\")\n",
    "gvp.models = importlib.import_module(\"gvp-pytorch.gvp.models\")\n",
    "gvp.data = importlib.import_module(\"gvp-pytorch.gvp.data\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPLACE WITH SIMPLE IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_irreps(hidden_features, lmax):\n",
    "    \"\"\"Divide subspaces equally over the feature budget\"\"\"\n",
    "    N = int(hidden_features / (lmax + 1))\n",
    "\n",
    "    irreps = []\n",
    "    for l, irrep in enumerate(Irreps.spherical_harmonics(lmax)):\n",
    "        n = int(N / (2 * l + 1))\n",
    "\n",
    "        irreps.append(str(n) + \"x\" + str(irrep[1]))\n",
    "\n",
    "    irreps = \"+\".join(irreps)\n",
    "\n",
    "    irreps = Irreps(irreps)\n",
    "\n",
    "    # Don't short sell yourself, add some more trivial irreps to fill the gap\n",
    "    gap = hidden_features - irreps.dim\n",
    "    if gap > 0:\n",
    "        irreps = Irreps(\"{}x0e\".format(gap)) + irreps\n",
    "        irreps = irreps.simplify()\n",
    "\n",
    "    return irreps\n",
    "\n",
    "def compute_gate_irreps(irreps_out):\n",
    "    \"\"\"Compute irreps_scalars, irreps\"\"\"\n",
    "    irreps_scalars = Irreps([(mul, ir) for mul, ir in irreps_out if ir.l == 0])\n",
    "    irreps_gated = Irreps([(mul, ir) for mul, ir in irreps_out if ir.l > 0])\n",
    "    irreps_gates = Irreps([(mul, \"0e\") for mul, _ in irreps_gated]).simplify()\n",
    "\n",
    "    return irreps_scalars, irreps_gated, irreps_gates\n",
    "\n",
    "class Convolution(nn.Module):\n",
    "    \"\"\" SE(3) equivariant convolution, parameterised by a radial network \"\"\"\n",
    "    def __init__(self, irreps_in1, irreps_in2, irreps_out):\n",
    "        super().__init__()\n",
    "        self.irreps_in1 = irreps_in1\n",
    "        self.irreps_in2 = irreps_in2\n",
    "        self.irreps_out = irreps_out\n",
    "        self.tp =  o3.FullyConnectedTensorProduct(\n",
    "            irreps_in1,\n",
    "            irreps_in2,\n",
    "            irreps_out,\n",
    "            irrep_normalization=\"component\",\n",
    "            path_normalization=\"element\",\n",
    "            internal_weights=False,\n",
    "            shared_weights=False\n",
    "        )\n",
    "\n",
    "        self.radial_net = RadialNet(self.tp.weight_numel)\n",
    "\n",
    "    def forward(self, x, rel_pos_sh, distance):\n",
    "        \"\"\"\n",
    "        Features of shape [E, irreps_in1.dim]\n",
    "        rel_pos_sh of shape [E, irreps_in2.dim]\n",
    "        distance of shape [E, 1]\n",
    "        \"\"\"\n",
    "        weights = self.radial_net(distance)\n",
    "        return self.tp(x, rel_pos_sh, weights)\n",
    "\n",
    "class RadialNet(nn.Module):\n",
    "    def __init__(self, num_weights):\n",
    "        super().__init__()\n",
    "\n",
    "        num_basis = 10\n",
    "        basis = tg.nn.models.dimenet.BesselBasisLayer(num_basis, cutoff=4)\n",
    "\n",
    "        self.net = nn.Sequential(basis,\n",
    "                                nn.Linear(num_basis, 16),\n",
    "                                nn.SiLU(),\n",
    "                                nn.Linear(16, num_weights))\n",
    "    def forward(self, dist):\n",
    "        return self.net(dist.squeeze(-1))\n",
    "\n",
    "\n",
    "class ConvLayerSE3(tg.nn.MessagePassing):\n",
    "    def __init__(self, irreps_in1, irreps_in2, irreps_out, activation=True):\n",
    "        super().__init__(aggr=\"add\")\n",
    "\n",
    "        self.irreps_in1 = irreps_in1\n",
    "        self.irreps_in2 = irreps_in2\n",
    "        self.irreps_out = irreps_out\n",
    "\n",
    "        irreps_scalars, irreps_gated, irreps_gates = compute_gate_irreps(irreps_out)\n",
    "        self.conv = Convolution(irreps_in1, irreps_in2, irreps_gates + irreps_out)\n",
    "\n",
    "        if activation:\n",
    "            self.gate = Gate(irreps_scalars, [nn.SiLU()], irreps_gates, [nn.Sigmoid()], irreps_gated)\n",
    "        else:\n",
    "            self.gate = nn.Identity()\n",
    "\n",
    "    def forward(self, edge_index, x, rel_pos_sh, dist):\n",
    "        x = self.propagate(edge_index, x=x, rel_pos_sh=rel_pos_sh, dist=dist)\n",
    "        x = self.gate(x)\n",
    "        return x\n",
    "\n",
    "    def message(self, x_j, rel_pos_sh, dist):\n",
    "        return self.conv(x_j, rel_pos_sh, dist)\n",
    "\n",
    "class ConvModel(nn.Module):\n",
    "    def __init__(self, irreps_in, irreps_hidden, irreps_edge, irreps_out, depth, max_z:int=atom3dutils._NUM_ATOM_TYPES):\n",
    "        super().__init__()\n",
    "\n",
    "        self.irreps_in = irreps_in\n",
    "        self.irreps_hidden = irreps_hidden\n",
    "        self.irreps_edge = irreps_edge\n",
    "        self.irreps_out = irreps_out\n",
    "\n",
    "        self.embedder = nn.Embedding(max_z, irreps_in.dim)\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(ConvLayerSE3(irreps_in, irreps_edge, irreps_hidden))\n",
    "        for i in range(depth-2):\n",
    "            self.layers.append(ConvLayerSE3(irreps_hidden, irreps_edge, irreps_hidden))\n",
    "        self.layers.append(ConvLayerSE3(irreps_hidden, irreps_edge, irreps_out, activation=False))\n",
    "\n",
    "    def forward(self, graph):\n",
    "        edge_index = graph.edge_index\n",
    "        z = graph.z\n",
    "        pos = graph.pos\n",
    "        batch = graph.batch\n",
    "\n",
    "        print(\"edge index\", edge_index)\n",
    "        print(\"z\", z)\n",
    "        print(\"pos\", pos)\n",
    "        print(\"batch\", batch)\n",
    "\n",
    "        # Prepare quantities for convolutional layers\n",
    "        # Index of source and target node\n",
    "        src, tgt = edge_index[0], edge_index[1]\n",
    "        # Vector pointing from the source node to the target node\n",
    "        rel_pos = pos[tgt] - pos[src]\n",
    "        # That vector in Spherical Harmonics\n",
    "        rel_pos_sh = o3.spherical_harmonics(self.irreps_edge, rel_pos, normalize=True)\n",
    "        # The norm of that vector\n",
    "        dist = torch.linalg.vector_norm(rel_pos, dim=-1, keepdims=True)\n",
    "\n",
    "        # Embed atom one-hot\n",
    "        x = self.embedder(z)\n",
    "\n",
    "        # Convolve nodes\n",
    "        for layer in self.layers:\n",
    "            x = layer(edge_index, x, rel_pos_sh, dist)\n",
    "\n",
    "        # 1-dim output, squeeze it out\n",
    "        x = x.squeeze(-1)\n",
    "        \n",
    "        # Global pooling of node features\n",
    "        x = tg.nn.global_mean_pool(x, batch)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Equivariance: Robustness in Protein Models with GVP\n",
    "\n",
    "Equivariance is the consistency of a model's output with regard to particular input transformations. When the output is unaffected by changes made to the input, a model is said to be equivariant. For example, in computer vision tasks, an equivariant model will produce consistent predictions regardless of the translation, rotation, or scaling applied to the input image. Verifying and quantifying equivariance to rotations is crucial to establish the reliability and robustness of models that analyze protein structures.\n",
    "\n",
    "In this demo, we investigate the equivariance to rotations of the GVP and our implementation of the steerable MLP. Our objective is to evaluate the robustness and consistency of the models' output when subjected to rotations.\n",
    "\n",
    "To do so, we first create random `300` random nodes, with each node having `100` scalar features and `16` vector features. The edges have `32` scalar features and `1` vector feature. We can randomly generate these node and edge features. Lastly, we define the edge index, which has the information about from where to which node an edge is going."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node scalar features torch.Size([300, 100])\n",
      "Node vector features torch.Size([300, 16, 3])\n",
      "Edge scalar features torch.Size([10000, 32])\n",
      "Edge vector features torch.Size([10000, 1, 3])\n",
      "Edge index torch.Size([2, 10000])\n"
     ]
    }
   ],
   "source": [
    "n_nodes = 300\n",
    "n_edges = 10000\n",
    "node_dim = (100, 16)\n",
    "edge_dim = (32, 1)\n",
    "\n",
    "nodes = gvp.randn(n_nodes, node_dim, device=device)\n",
    "edges = gvp.randn(n_edges, edge_dim, device=device)\n",
    "edge_index = torch.randint(0, n_nodes, (2, n_edges), device=device)\n",
    "\n",
    "print(\"Node scalar features\", nodes[0].shape)\n",
    "print(\"Node vector features\", nodes[1].shape)\n",
    "print(\"Edge scalar features\", edges[0].shape)\n",
    "print(\"Edge vector features\", edges[1].shape)\n",
    "print(\"Edge index\", edge_index.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's enhance the clarity of the tests regarding our desired objectives. Our aim is to ensure that the scalar output features of the model remain unchanged under rotation, as scalars possess inherent rotation invariance. Additionally, we expect the vector features to exhibit rotation equivariance, implying that the model's output, after rotating the original vector input, should be identical to rotating the output obtained by passing the original vector input through the model. Or also in another representation:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\text{Invariance:}   && \\text{model}(\\text{rotation}(\\text{scalars})) &= \\text{model}(\\text{scalars})         \\\\\n",
    "\\text{Equivariance:} && \\text{model}(\\text{rotation}(\\text{vectors})) &= \\text{rotation}(\\text{model}(\\text{vectors})).\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_equivariance_GVP(model, nodes, edges):\n",
    "    \n",
    "    random = torch.as_tensor(Rotation.random().as_matrix(), \n",
    "                             dtype=torch.float32, device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        out_s, out_v = model(nodes, edges)\n",
    "        n_v_rot, e_v_rot = nodes[1] @ random, edges[1] @ random\n",
    "        out_v_rot = out_v @ random\n",
    "        out_s_prime, out_v_prime = model((nodes[0], n_v_rot), (edges[0], e_v_rot))\n",
    "        \n",
    "        assert torch.allclose(out_s, out_s_prime, atol=1e-5, rtol=1e-4)\n",
    "        assert torch.allclose(out_v_rot, out_v_prime, atol=1e-5, rtol=1e-4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define a class that has tests for the GVP, GVP with vector gating and GVP convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EquivarianceTestGVP(unittest.TestCase):\n",
    "\n",
    "    \"\"\"\n",
    "    This is a class that tests whether the GVP with and without vector gating, and\n",
    "    the GVP convolutional layer are equivariant to rotation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def test_gvp(self):\n",
    "        model = gvp.GVP(node_dim, node_dim).to(device).eval()\n",
    "        model_fn = lambda h_V, h_E: model(h_V)\n",
    "        test_equivariance_GVP(model_fn, nodes, edges)\n",
    "        \n",
    "    def test_gvp_vector_gate(self):\n",
    "        model = gvp.GVP(node_dim, node_dim, vector_gate=True).to(device).eval()\n",
    "        model_fn = lambda h_V, h_E: model(h_V)\n",
    "        test_equivariance_GVP(model_fn, nodes, edges)\n",
    "\n",
    "    def test_gvp_conv_layer_vector_gate(self):\n",
    "        model = gvp.GVPConvLayer(node_dim, edge_dim, vector_gate=True).to(device).eval()\n",
    "        model_fn = lambda h_V, h_E: model(h_V, edge_index, h_E,\n",
    "                                          autoregressive_x=h_V)\n",
    "        test_equivariance_GVP(model_fn, nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.122s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude from this test that he scalar features are indeed invariant to rotation and the vector features are equivariant to rotation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Equivariance: Robustness in Protein Models with steerable MLP\n",
    "\n",
    "Now we can perform the same tests using the steerable MLP. The only thing we will need to change is how the input is handled. Since the steerable MLP works with irreducible representations, we will first define these for the nodes, edges and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input irreps 10x0e+10x1e\n",
      "Edge irreps 32x0e+1x1o\n",
      "Output irreps 20x0e+10x1e\n",
      "Dim embedding irreps: 40\n"
     ]
    }
   ],
   "source": [
    "# Nodes are encoded using 16 scalars (type-0) and 16 geo vector (type-1)\n",
    "irreps_node = Irreps(\"10x0e+10x1e\")\n",
    "# Edges are encoded using 32 scalars and 1 geo vector (type-1)\n",
    "irreps_edge = Irreps(\"32x0e+1x1o\")\n",
    "# Output is 16 scalars (type-0) and 16 geo vector (type-1)\n",
    "irreps_out = Irreps(\"20x0e + 10x1e\")\n",
    "\n",
    "# irreps_scalars, irreps_gated, irreps_gates = compute_gate_irreps(irreps_out)\n",
    "# irreps_final = irreps_gates + irreps_out\n",
    "\n",
    "dim_emb = irreps_node.dim\n",
    "\n",
    "print(\"Input irreps\", irreps_node)\n",
    "print(\"Edge irreps\", irreps_edge)\n",
    "print(\"Output irreps\", irreps_out)\n",
    "# print(\"Output + Gates irreps\", irreps_final)\n",
    "print(\"Dim embedding irreps:\", dim_emb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a random graph using random positions and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the positions of the nodes\n",
    "pos = torch.randn(size=(n_nodes,3))\n",
    "\n",
    "# Node embedding\n",
    "x = torch.randn(size=(n_nodes,dim_emb))\n",
    "\n",
    "# How these nodes are connected (doesnt matter)\n",
    "edge_index = torch.randint(0, n_nodes, (2, n_edges), device=device)\n",
    "\n",
    "# All nodes are in this \"batch\" -> protein structure\n",
    "batch = torch.ones(size=(n_nodes,))\n",
    "\n",
    "# Edge features: vector from source to targer\n",
    "rel_pos = pos[edge_index[0]] - pos[edge_index[1]]\n",
    "\n",
    "# Edge features in Spherical Harmonics\n",
    "rel_pos_sh = o3.spherical_harmonics(irreps_edge, rel_pos, normalize=True)\n",
    "\n",
    "# Norm of the edge features\n",
    "dist = torch.linalg.vector_norm(rel_pos, dim=-1, keepdims=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input is defined, so let's define the model, the convolutional layer that is equivariant to SE3 rotations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = ConvLayerSE3(\n",
    "    irreps_in1=irreps_node,\n",
    "    irreps_in2=irreps_edge,\n",
    "    irreps_out=irreps_out,\n",
    ")\n",
    "\n",
    "out = model(edge_index, x, rel_pos_sh, dist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a random 3D rotation matrix and get the right representations for the input and output irreducible representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot = o3.rand_matrix()\n",
    "D_in = irreps_node.D_from_matrix(rot)\n",
    "D_out = irreps_out.D_from_matrix(rot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can rotate the output of the convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate after\n",
    "out_rot_after = out @ D_out.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or rotate the input of the convolutional layer and rotate this output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate before\n",
    "pos_rot = pos @ rot.T\n",
    "rel_pos_rot = pos_rot[edge_index[0]] - pos_rot[edge_index[1]]\n",
    "rel_pos_sh_rot = o3.spherical_harmonics(irreps_edge, rel_pos_rot, normalize=True)\n",
    "out_rot_before = model(edge_index, x @ D_in.T, rel_pos_sh_rot, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(out_rot_after, out_rot_before, rtol=1e-4, atol=1e-4, equal_nan=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we can conclude that the model is equivariant to rotation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
