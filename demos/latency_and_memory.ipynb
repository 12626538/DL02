{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latency and memory\n",
    "\n",
    "## How to run this file on the lisa cluster\n",
    "\n",
    "Start by pulling the lastest version of the repository, if necessary re-add the ssh-key to the agent.  ([See here](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent?platform=linux)), i.e.\n",
    "\n",
    "```sh\n",
    "eval \"$(ssh-agent -s)\"\n",
    "ssh-add ~/.ssh/id_ed25519\n",
    "```\n",
    "\n",
    "Then activate the correct modules (`2022` and `Anaconda3/2022.05`) and activate the `gvp` source.  Finally, actually run the notebook with \n",
    "\n",
    "```sh\n",
    "jupyter nbconvert \"latency and memory.ipynb\" --to notebook --execute --inplace --allow-errors\n",
    "```\n",
    "\n",
    "Make sure the environment contains the following packages: `ipywidgets`, `jupyter`, `notebook`, `torch`, `gvp`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "* Import things necessary for running GVP and SMLP, \n",
    "* Setup which task we analyse, \n",
    "* ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:58:42.110631Z",
     "iopub.status.busy": "2023-05-26T11:58:42.110036Z",
     "iopub.status.idle": "2023-05-26T11:58:42.121784Z",
     "shell.execute_reply": "2023-05-26T11:58:42.120968Z"
    }
   },
   "outputs": [],
   "source": [
    "# Supresses the following warning:\n",
    "#   UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class.\n",
    "#   This should only matter to you if you are using storages directly.\n",
    "#   To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:58:42.126273Z",
     "iopub.status.busy": "2023-05-26T11:58:42.125895Z",
     "iopub.status.idle": "2023-05-26T11:58:50.650627Z",
     "shell.execute_reply": "2023-05-26T11:58:50.649495Z"
    }
   },
   "outputs": [],
   "source": [
    "import time, torch, os, sys\n",
    "import numpy as np\n",
    "\n",
    "from e3nn.o3 import Irreps\n",
    "from torch.profiler import profile, ProfilerActivity\n",
    "\n",
    "# for fixing relative import issues\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.run_atom3d import get_datasets, get_model\n",
    "from src.steerable_mlp import ConvModel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task setup\n",
    "Adjust the data and model directories to match up with the correct folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:58:50.657864Z",
     "iopub.status.busy": "2023-05-26T11:58:50.656730Z",
     "iopub.status.idle": "2023-05-26T11:58:50.699670Z",
     "shell.execute_reply": "2023-05-26T11:58:50.698302Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../atom3d-data/\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device != \"cuda\":\n",
    "    exit()\n",
    "\n",
    "TASK = \"LBA\"\n",
    "\"\"\"Task to test for model latency.\"\"\"\n",
    "LBA_SPLIT = 30\n",
    "# SPLIT = 60\n",
    "\n",
    "DATASET_SPLIT = \"train\"\n",
    "\"\"\"Dataset partition from which the sample is chosen.\"\"\"\n",
    "# Select from these values\n",
    "DATASET_SPLIT = [\"train\", \"val\", \"test\"].index(DATASET_SPLIT)\n",
    "SAMPLE_INDEX = 10\n",
    "\"\"\"Dataset index to use for testing the latency and memory.\"\"\"\n",
    "\n",
    "BEST_GVP_MODEL = \"../src/reproduced_models/LBA_lba-split=30_47.pt\"\n",
    "\"\"\"Path to the best trained relevant model.\"\"\"\n",
    "BEST_SMLP_MODEL = \"../src/sMLPmodels/LBA-lba_split=30-epoch=10.ckpt\"\n",
    "\"\"\"Path to the best trained relevant model.\"\"\"\n",
    "USE_DENSE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:58:50.705493Z",
     "iopub.status.busy": "2023-05-26T11:58:50.704921Z",
     "iopub.status.idle": "2023-05-26T11:58:52.497089Z",
     "shell.execute_reply": "2023-05-26T11:58:52.496649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[551, 3], edge_index=[2, 13194], atoms=[551], edge_s=[13194, 16], edge_v=[13194, 1, 3], label=6.85, lig_flag=[551], batch=[551], z=[551], pos=[551, 3])\n"
     ]
    }
   ],
   "source": [
    "datasets = get_datasets(TASK, DATA_DIR, LBA_SPLIT)\n",
    "\n",
    "gvp_model = get_model(TASK).to(device)\n",
    "# gvp_model = nn.DataParallel(gvp_model)  # Add parallel to fix OOM issues?\n",
    "gvp_model.load_state_dict(torch.load(BEST_GVP_MODEL), strict=False)\n",
    "\n",
    "dataset_sample = datasets[DATASET_SPLIT][SAMPLE_INDEX].to(device)\n",
    "# This is required for taking the scattermean of the graph\n",
    "dataset_sample.batch = torch.zeros_like(dataset_sample.atoms)\n",
    "# Fix for our steerable.\n",
    "dataset_sample.z = dataset_sample.atoms\n",
    "dataset_sample.pos = dataset_sample.x\n",
    "\n",
    "print(dataset_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:58:52.534153Z",
     "iopub.status.busy": "2023-05-26T11:58:52.533717Z",
     "iopub.status.idle": "2023-05-26T11:58:53.095827Z",
     "shell.execute_reply": "2023-05-26T11:58:53.094740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['embedder.weight', 'layers.0.conv.tp.weight', 'layers.0.conv.tp.output_mask', 'layers.0.conv.radial_net.net.0.freq', 'layers.0.conv.radial_net.net.1.weight', 'layers.0.conv.radial_net.net.1.bias', 'layers.0.conv.radial_net.net.3.weight', 'layers.0.conv.radial_net.net.3.bias', 'layers.0.gate.mul.weight', 'layers.0.gate.mul.output_mask', 'layers.1.conv.tp.weight', 'layers.1.conv.tp.output_mask', 'layers.1.conv.radial_net.net.0.freq', 'layers.1.conv.radial_net.net.1.weight', 'layers.1.conv.radial_net.net.1.bias', 'layers.1.conv.radial_net.net.3.weight', 'layers.1.conv.radial_net.net.3.bias', 'layers.1.gate.mul.weight', 'layers.1.gate.mul.output_mask', 'layers.2.conv.tp.weight', 'layers.2.conv.tp.output_mask', 'layers.2.conv.radial_net.net.0.freq', 'layers.2.conv.radial_net.net.1.weight', 'layers.2.conv.radial_net.net.1.bias', 'layers.2.conv.radial_net.net.3.weight', 'layers.2.conv.radial_net.net.3.bias'], unexpected_keys=['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def balanced_irreps(hidden_features: int, lmax: int) -> Irreps:\n",
    "    \"\"\"Divide subspaces equally over the feature budget\"\"\"\n",
    "    N = int(hidden_features / (lmax + 1))\n",
    "    irreps = []\n",
    "    for l, irrep in enumerate(Irreps.spherical_harmonics(lmax)):\n",
    "        n = int(N / (2 * l + 1))\n",
    "        irreps.append(str(n) + \"x\" + str(irrep[1]))\n",
    "    irreps = \"+\".join(irreps)\n",
    "    irreps = Irreps(irreps)\n",
    "    gap = hidden_features - irreps.dim\n",
    "    if gap > 0:\n",
    "        irreps = Irreps(\"{}x0e\".format(gap)) + irreps\n",
    "        irreps = irreps.simplify()\n",
    "    return irreps\n",
    "\n",
    "irreps_in = Irreps(\"32x0e\")\n",
    "irreps_hidden = balanced_irreps(128, 1)\n",
    "irreps_edge = Irreps.spherical_harmonics(1)\n",
    "irreps_out = Irreps(\"16x0e\") if USE_DENSE else Irreps(\"1x0e\")\n",
    "smlp_model = ConvModel(\n",
    "    irreps_in=irreps_in,\n",
    "    irreps_hidden=irreps_hidden,\n",
    "    irreps_edge=irreps_edge,\n",
    "    irreps_out=irreps_out,\n",
    "    depth=3,\n",
    "    dense=USE_DENSE,\n",
    ").to(device)\n",
    "smlp_model.load_state_dict(torch.load(BEST_SMLP_MODEL), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:58:53.101022Z",
     "iopub.status.busy": "2023-05-26T11:58:53.100552Z",
     "iopub.status.idle": "2023-05-26T11:59:04.271274Z",
     "shell.execute_reply": "2023-05-26T11:59:04.270289Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-05-26 22:53:55 36294:36294 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-05-26 22:53:58 36294:36294 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-05-26 22:53:58 36294:36294 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "# Burn a few times to prevent extra overhead for first CUDA profiling\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "             profile_memory=True) as prof:\n",
    "    for _ in range(30):\n",
    "        gvp_model(dataset_sample)\n",
    "        smlp_model(dataset_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:59:04.275869Z",
     "iopub.status.busy": "2023-05-26T11:59:04.275575Z",
     "iopub.status.idle": "2023-05-26T11:59:04.279737Z",
     "shell.execute_reply": "2023-05-26T11:59:04.279200Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_latency_memory(model, dataset_sample):\n",
    "    memory_start = torch.cuda.memory_allocated()\n",
    "    latencies = []\n",
    "    for _ in range(100):\n",
    "        latency_start = time.perf_counter()\n",
    "        out = model(dataset_sample)\n",
    "        latency_end = time.perf_counter()\n",
    "        latencies.append(latency_end - latency_start)\n",
    "    memory_end = torch.cuda.memory_allocated()\n",
    "    return latencies, memory_end - memory_start"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:59:04.283460Z",
     "iopub.status.busy": "2023-05-26T11:59:04.283196Z",
     "iopub.status.idle": "2023-05-26T11:59:46.780555Z",
     "shell.execute_reply": "2023-05-26T11:59:46.779955Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-05-26 22:54:04 36294:36294 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-05-26 22:54:07 36294:36294 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-05-26 22:54:07 36294:36294 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "STAGE:2023-05-26 22:54:22 36294:36294 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-05-26 22:54:25 36294:36294 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-05-26 22:54:25 36294:36294 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.mean(withgrad_latency)=0.028397920759980478\n",
      "np.std(withgrad_latency)=0.001347460038363938\n",
      "np.mean(gradless_latency)=0.02743657376993724\n",
      "np.std(gradless_latency)=0.0014193098946963653\n",
      "\n",
      "withgrad_memory=485300736\n",
      "gradless_memory=512\n"
     ]
    }
   ],
   "source": [
    "gvp_model.train()\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "             profile_memory=True) as prof_train:\n",
    "    withgrad_latency, withgrad_memory = test_latency_memory(gvp_model, dataset_sample)\n",
    "    # out = gvp_model(dataset_sample)\n",
    "\n",
    "\n",
    "gvp_model.eval()\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "            profile_memory=True) as prof_test:\n",
    "    with torch.no_grad():\n",
    "        gradless_latency, gradless_memory = test_latency_memory(gvp_model, dataset_sample)\n",
    "        # out = gvp_model(dataset_sample)\n",
    "\n",
    "print(f\"{np.mean(withgrad_latency)=}\")\n",
    "print(f\"{np.std(withgrad_latency)=}\")\n",
    "print(f\"{np.mean(gradless_latency)=}\")\n",
    "print(f\"{np.std(gradless_latency)=}\")\n",
    "print()\n",
    "print(f\"{withgrad_memory=}\")\n",
    "print(f\"{gradless_memory=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:59:46.785081Z",
     "iopub.status.busy": "2023-05-26T11:59:46.784811Z",
     "iopub.status.idle": "2023-05-26T11:59:46.789851Z",
     "shell.execute_reply": "2023-05-26T11:59:46.788874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "withgrad_latency=[0.02941793699937989, 0.03024948799975391, 0.03107708800052933, 0.03152759400109062, 0.030469551000351203, 0.027549861999432324, 0.02838385399991239, 0.03034137900067435, 0.02988938400085317, 0.027877545000592363, 0.028723559000354726, 0.030156337001244538, 0.03805791800004954, 0.029140702001313912, 0.029382736998741166, 0.02696531500077981, 0.026971045999744092, 0.028546706000270206, 0.02732309000020905, 0.027732255999580957, 0.028429602998585324, 0.027029966999180033, 0.02693881500090356, 0.028392784000971005, 0.02826142300000356, 0.02702202600085002, 0.029093912000462296, 0.026965175000441377, 0.02702754699930665, 0.02818061099969782, 0.02777253599924734, 0.0280218279986002, 0.028134771000623005, 0.02718443699995987, 0.027049117001297418, 0.02834183400045731, 0.027667943999404088, 0.02803929000037897, 0.028633095998884528, 0.026852433999010827, 0.027679074999468867, 0.028258971999093774, 0.02864645699992252, 0.028158130999145214, 0.029006161001234432, 0.027489562999107875, 0.027469332000691793, 0.02922386399950483, 0.02839575399957539, 0.027389571001549484, 0.028528525999718113, 0.027676693998728297, 0.027787407001596875, 0.02832351200049743, 0.027898726999410428, 0.027679245000399533, 0.028225742000358878, 0.028193162001116434, 0.027478330999656464, 0.028537585998492432, 0.029644199999893317, 0.027768215999458334, 0.028295193000303698, 0.028646785000091768, 0.029167754999434692, 0.028073270001186756, 0.02755345299920009, 0.02799762799986638, 0.028113250999012962, 0.027069855999798165, 0.0281238610004948, 0.028556935998494737, 0.027302769998641452, 0.028827759000705555, 0.028585846001078608, 0.02712851700016472, 0.028595317000508658, 0.028192122001200914, 0.028437383998607402, 0.029086202001053607, 0.029050983001070563, 0.028035718998580705, 0.02705840700036788, 0.029538267001044005, 0.02836967399889545, 0.027785827000116115, 0.028943170998900314, 0.029882462000387022, 0.028134881000369205, 0.0267511319998448, 0.028606866999325575, 0.028732918999594403, 0.027979627000604523, 0.029128453999874182, 0.028872200000478188, 0.02830972199990356, 0.028073159999621566, 0.02868543799922918, 0.02840410399949178, 0.02741443099876051]\n",
      "gradless_latency=[0.03226948299925425, 0.02972804199998791, 0.028419893000318552, 0.027465052000479773, 0.029423506999592064, 0.02987545199903252, 0.02863676699962525, 0.026425288999234908, 0.028300592000960023, 0.02755085199896712, 0.036808021999604534, 0.02639883799929521, 0.02814044099977764, 0.027383640999687486, 0.026464157999726012, 0.028436553999199532, 0.027345561000402085, 0.02593187200000102, 0.028701868001007824, 0.026602660000207834, 0.02731653000046208, 0.026811333000296145, 0.026832603000002564, 0.02827039300063916, 0.02566856799967354, 0.02715137700033665, 0.028246533000128693, 0.027164958000867045, 0.026204386000244995, 0.02789186599875393, 0.026014612998551456, 0.027941237998675206, 0.02593726300074195, 0.027396950999900582, 0.028675616998953046, 0.02619132499967236, 0.02650121999977273, 0.027425121001215302, 0.027269030000752537, 0.02774659500028065, 0.028173380000225734, 0.026189496000370127, 0.028026088999467902, 0.026339448000726406, 0.026829833001102088, 0.029351134999160422, 0.0264677400009532, 0.026769292999233585, 0.028338142999928095, 0.02683087299919862, 0.027398240999900736, 0.027529863000381738, 0.026266365999617847, 0.028144500998678268, 0.02607412299948919, 0.027301320000333362, 0.02813275100015744, 0.026448318998518516, 0.02676069300105155, 0.02754921199993987, 0.02648245900127222, 0.027285649000987178, 0.02648328000032052, 0.027344090000042343, 0.028184631000840454, 0.02588588100115885, 0.02825477199985471, 0.02848790600000939, 0.026210026000626385, 0.027860365000378806, 0.027571393999096472, 0.026316686999052763, 0.027801935999377747, 0.028163381000922527, 0.026556168999377405, 0.02863453799909621, 0.027697735000401735, 0.026794802000949858, 0.02840053399995668, 0.026593770999170374, 0.02709492699978, 0.028331333000096492, 0.027883466000275803, 0.02583153100022173, 0.027562653998757014, 0.02603167300003406, 0.02745345199946314, 0.026018332999228733, 0.026723650998974335, 0.028104871000323328, 0.02603966400056379, 0.026746561999971163, 0.026873994000197854, 0.0268299819999811, 0.027370091000193497, 0.02606595399993239, 0.027077376998931868, 0.027512962999026058, 0.0257491789998312, 0.027458831000330974]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{withgrad_latency=}\")\n",
    "print(f\"{gradless_latency=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:59:46.793128Z",
     "iopub.status.busy": "2023-05-26T11:59:46.792585Z",
     "iopub.status.idle": "2023-05-26T12:00:01.561738Z",
     "shell.execute_reply": "2023-05-26T12:00:01.560885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================================================================================================================================================================================================\n",
      "This report only display top-level ops statistics\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::linear         1.98%      46.382ms        20.51%     479.884ms      44.026us       0.000us         0.00%        2.007s     184.088us           0 b           0 b      18.20 Gb     979.57 Mb         10900  \n",
      "                                ampere_sgemm_128x128_tt         0.00%       0.000us         0.00%       0.000us       0.000us        1.598s        62.99%        1.598s       1.453ms           0 b           0 b           0 b           0 b          1100  \n",
      "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     215.450ms         8.49%     215.450ms     143.633us           0 b           0 b           0 b           0 b          1500  \n",
      "                                              aten::cat         2.06%      48.176ms         2.87%      67.150ms      15.988us     208.499ms         8.22%     211.189ms      50.283us           0 b           0 b      24.94 Gb      24.94 Gb          4200  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     187.355ms         7.38%     187.355ms      50.636us           0 b           0 b           0 b           0 b          3700  \n",
      "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     168.344ms         6.63%     168.344ms      27.152us           0 b           0 b           0 b           0 b          6200  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us      60.244ms         2.37%      60.244ms      28.688us           0 b           0 b           0 b           0 b          2100  \n",
      "                                              aten::mul         2.13%      49.787ms         2.96%      69.326ms      15.071us      35.227ms         1.39%      56.369ms      12.254us         -16 b         -16 b       3.85 Gb       3.85 Gb          4600  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      49.162ms         1.94%      49.162ms       8.059us           0 b           0 b           0 b           0 b          6100  \n",
      "                                              aten::sum         2.25%      52.523ms         2.95%      68.927ms      17.674us      36.475ms         1.44%      49.008ms      12.566us           0 b           0 b       1.76 Gb       1.76 Gb          3900  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.339s\n",
      "Self CUDA time total: 2.537s\n",
      "\n",
      "===========================================================================================================================================================================================================================================================\n",
      "This report only display top-level ops statistics\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                              aten::cat         2.06%      48.176ms         2.87%      67.150ms      15.988us     208.499ms         8.22%     211.189ms      50.283us           0 b           0 b      24.94 Gb      24.94 Gb          4200  \n",
      "                                           aten::linear         1.98%      46.382ms        20.51%     479.884ms      44.026us       0.000us         0.00%        2.007s     184.088us           0 b           0 b      18.20 Gb     979.57 Mb         10900  \n",
      "                                             aten::relu         0.34%       7.874ms         1.09%      25.616ms      16.010us       0.000us         0.00%      39.225ms      24.516us           0 b           0 b       5.35 Gb           0 b          1600  \n",
      "                                           aten::square         0.25%       5.831ms         2.95%      68.918ms      17.671us       0.000us         0.00%      39.513ms      10.132us           0 b           0 b       5.16 Gb     118.68 Mb          3900  \n",
      "                                              aten::mul         2.13%      49.787ms         2.96%      69.326ms      15.071us      35.227ms         1.39%      56.369ms      12.254us         -16 b         -16 b       3.85 Gb       3.85 Gb          4600  \n",
      "                                            aten::clamp         1.76%      41.198ms         2.56%      59.829ms      13.598us      10.907ms         0.43%      15.938ms       3.622us           0 b           0 b       1.79 Gb       1.79 Gb          4400  \n",
      "                                              aten::sum         2.25%      52.523ms         2.95%      68.927ms      17.674us      36.475ms         1.44%      49.008ms      12.566us           0 b           0 b       1.76 Gb       1.76 Gb          3900  \n",
      "                                             aten::sqrt         1.59%      37.229ms         2.17%      50.823ms      13.032us      10.449ms         0.41%      20.488ms       5.253us           0 b           0 b       1.75 Gb       1.75 Gb          3900  \n",
      "                                          aten::sigmoid         1.18%      27.603ms         1.65%      38.594ms      14.844us       7.715ms         0.30%      11.818ms       4.545us           0 b           0 b       1.23 Gb       1.23 Gb          2600  \n",
      "                                              aten::add         1.35%      31.559ms         1.96%      45.869ms      11.467us       8.147ms         0.32%      10.873ms       2.718us         440 b         440 b     623.05 Mb     623.05 Mb          4000  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.339s\n",
      "Self CUDA time total: 2.537s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof_train.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10, top_level_events_only=True))\n",
    "print(prof_train.key_averages().table(sort_by=\"cuda_memory_usage\", row_limit=10, top_level_events_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T12:00:01.566786Z",
     "iopub.status.busy": "2023-05-26T12:00:01.566438Z",
     "iopub.status.idle": "2023-05-26T12:00:14.716346Z",
     "shell.execute_reply": "2023-05-26T12:00:14.715071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================================================================================================================================================================================================\n",
      "This report only display top-level ops statistics\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::linear         1.51%      35.219ms        17.53%     409.280ms      37.549us       0.000us         0.00%        1.917s     175.903us           0 b           0 b      18.04 Gb     637.03 Mb         10900  \n",
      "                                ampere_sgemm_128x128_tt         0.00%       0.000us         0.00%       0.000us       0.000us        1.613s        63.43%        1.613s       1.466ms           0 b           0 b           0 b           0 b          1100  \n",
      "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     230.482ms         9.06%     230.482ms     153.655us           0 b           0 b           0 b           0 b          1500  \n",
      "                                              aten::cat         1.63%      38.130ms         2.43%      56.675ms      13.494us     195.325ms         7.68%     195.325ms      46.506us           0 b           0 b      24.67 Gb      24.67 Gb          4200  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     174.487ms         6.86%     174.487ms      47.159us           0 b           0 b           0 b           0 b          3700  \n",
      "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     169.747ms         6.68%     169.747ms      27.379us           0 b           0 b           0 b           0 b          6200  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us      60.337ms         2.37%      60.337ms      28.732us           0 b           0 b           0 b           0 b          2100  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      48.313ms         1.90%      48.313ms       7.920us           0 b           0 b           0 b           0 b          6100  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      38.917ms         1.53%      38.917ms       9.979us           0 b           0 b           0 b           0 b          3900  \n",
      "                                             aten::relu         0.21%       4.813ms         0.98%      22.906ms      14.316us       0.000us         0.00%      37.563ms      23.477us           0 b           0 b       5.35 Gb           0 b          1600  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.334s\n",
      "Self CUDA time total: 2.543s\n",
      "\n",
      "===========================================================================================================================================================================================================================================================\n",
      "This report only display top-level ops statistics\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                              aten::cat         1.63%      38.130ms         2.43%      56.675ms      13.494us     195.325ms         7.68%     195.325ms      46.506us           0 b           0 b      24.67 Gb      24.67 Gb          4200  \n",
      "                                           aten::linear         1.51%      35.219ms        17.53%     409.280ms      37.549us       0.000us         0.00%        1.917s     175.903us           0 b           0 b      18.04 Gb     637.03 Mb         10900  \n",
      "                                             aten::relu         0.21%       4.813ms         0.98%      22.906ms      14.316us       0.000us         0.00%      37.563ms      23.477us           0 b           0 b       5.35 Gb           0 b          1600  \n",
      "                                           aten::square         0.29%       6.709ms         2.59%      60.486ms      15.509us       0.000us         0.00%      37.018ms       9.492us           0 b           0 b       5.14 Gb     273.88 Mb          3900  \n",
      "                                              aten::mul         1.05%      24.463ms         1.53%      35.734ms      13.744us      33.885ms         1.33%      33.885ms      13.033us           0 b           0 b       3.74 Gb       3.74 Gb          2600  \n",
      "                                              aten::sum         1.90%      44.244ms         2.56%      59.674ms      15.301us      33.798ms         1.33%      33.798ms       8.666us           0 b           0 b       2.04 Gb       2.04 Gb          3900  \n",
      "                                             aten::sqrt         1.08%      25.193ms         1.63%      37.992ms       9.742us      10.170ms         0.40%      10.170ms       2.608us           0 b           0 b       2.00 Gb       2.00 Gb          3900  \n",
      "                                            aten::clamp         1.46%      34.149ms         2.23%      52.056ms      11.831us      10.645ms         0.42%      10.645ms       2.419us           0 b           0 b       1.71 Gb       1.71 Gb          4400  \n",
      "                                          aten::sigmoid         0.87%      20.201ms         1.33%      31.099ms      11.961us       7.702ms         0.30%       7.702ms       2.962us           0 b           0 b       1.23 Gb       1.23 Gb          2600  \n",
      "                                              aten::add         1.28%      29.802ms         1.96%      45.835ms      11.459us       8.418ms         0.33%       8.418ms       2.104us         312 b         312 b     623.05 Mb     623.05 Mb          4000  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.334s\n",
      "Self CUDA time total: 2.543s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof_test.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10, top_level_events_only=True))\n",
    "print(prof_test.key_averages().table(sort_by=\"cuda_memory_usage\", row_limit=10, top_level_events_only=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steerable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T12:00:14.722310Z",
     "iopub.status.busy": "2023-05-26T12:00:14.721442Z",
     "iopub.status.idle": "2023-05-26T12:00:33.892698Z",
     "shell.execute_reply": "2023-05-26T12:00:33.891340Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-05-26 22:55:02 36294:36294 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-05-26 22:55:03 36294:36294 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-05-26 22:55:03 36294:36294 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "STAGE:2023-05-26 22:55:07 36294:36294 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-05-26 22:55:09 36294:36294 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-05-26 22:55:09 36294:36294 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.mean(withgrad_latency)=0.010318623949933681\n",
      "np.std(withgrad_latency)=0.0013195587161539775\n",
      "np.mean(gradless_latency)=0.009912540109980909\n",
      "np.std(gradless_latency)=0.0005958322722224627\n",
      "\n",
      "withgrad_memory=706749952\n",
      "gradless_memory=512\n"
     ]
    }
   ],
   "source": [
    "gvp_model.train()\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "             profile_memory=True) as prof_train:\n",
    "    withgrad_latency, withgrad_memory = test_latency_memory(smlp_model, dataset_sample)\n",
    "    # out = gvp_model(dataset_sample)\n",
    "\n",
    "\n",
    "gvp_model.eval()\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "            profile_memory=True) as prof_test:\n",
    "    with torch.no_grad():\n",
    "        gradless_latency, gradless_memory = test_latency_memory(smlp_model, dataset_sample)\n",
    "        # out = gvp_model(dataset_sample)\n",
    "\n",
    "print(f\"{np.mean(withgrad_latency)=}\")\n",
    "print(f\"{np.std(withgrad_latency)=}\")\n",
    "print(f\"{np.mean(gradless_latency)=}\")\n",
    "print(f\"{np.std(gradless_latency)=}\")\n",
    "print()\n",
    "print(f\"{withgrad_memory=}\")\n",
    "print(f\"{gradless_memory=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T12:00:33.898447Z",
     "iopub.status.busy": "2023-05-26T12:00:33.897637Z",
     "iopub.status.idle": "2023-05-26T12:00:33.904645Z",
     "shell.execute_reply": "2023-05-26T12:00:33.903538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "withgrad_latency=[0.018917412000519107, 0.013464051999108051, 0.009913267000229098, 0.010768768001071294, 0.011467056001492892, 0.009082956001293496, 0.011122882999188732, 0.010646086000633659, 0.009072086999367457, 0.01115228300113813, 0.009541612000248278, 0.010101908999786247, 0.011302853999950457, 0.009239147999323905, 0.011655709000478964, 0.011258713999268366, 0.009558992000165745, 0.011496747998535284, 0.010627176001435146, 0.009756256000400754, 0.01061187599952973, 0.008987033999801497, 0.01125229399985983, 0.00983872599863389, 0.009477190998950391, 0.010618095000609173, 0.009424881998711498, 0.010792778000904946, 0.009886857000310556, 0.00948845099992468, 0.011331584999425104, 0.0088791329999367, 0.010206269998889184, 0.009661004000008688, 0.009672153999417787, 0.01151277799908712, 0.00903125599870691, 0.010042007999800262, 0.010192319999987376, 0.009418179999556742, 0.011632959000053233, 0.009020655001222622, 0.010135259999515256, 0.010762488000182202, 0.009352781000416144, 0.014496584999506013, 0.009563662999426015, 0.009086725998713518, 0.010797157998240436, 0.008817511999950511, 0.009956326999599696, 0.009777425000720541, 0.009753546000865754, 0.010916999999608379, 0.008968883999841637, 0.010834089000127278, 0.010263141000905307, 0.009817624999413965, 0.01080688900037785, 0.009214646999680554, 0.009919598000124097, 0.009756515000844956, 0.009675544000856462, 0.010523654000280658, 0.008935343999837642, 0.013547273998483433, 0.010530735000429559, 0.009350610000183224, 0.010780146998513374, 0.01085726900055306, 0.009911266999552026, 0.011377986000297824, 0.008872813999914797, 0.010068707999380422, 0.009792794999157195, 0.009904096999889589, 0.010716637001678464, 0.00929072799954156, 0.010046350000266102, 0.011253384000156075, 0.009059656000317773, 0.011353525000231457, 0.009351650000098743, 0.0100882789993193, 0.010335161998227704, 0.009308370001235744, 0.010832446998392697, 0.009285709998948732, 0.010126680001121713, 0.010632736000843579, 0.009025834999192739, 0.011240752999583492, 0.010505555001145694, 0.009651504000430577, 0.010401723999166279, 0.009732442998938495, 0.01080791899948963, 0.010157610000533168, 0.009677284000645159, 0.010729897001510835]\n",
      "gradless_latency=[0.010787067998535349, 0.00915043799977866, 0.010688176000257954, 0.009377860000313376, 0.010798928000440355, 0.009806854999624193, 0.0096764539994183, 0.00989565700001549, 0.009604773000319256, 0.010594225999739137, 0.009456090001549455, 0.009712855000543641, 0.010716366999986349, 0.009394339998834766, 0.010423013000036008, 0.010155039999517612, 0.010225450998404995, 0.00994468700082507, 0.009032275000208756, 0.010937119999653078, 0.00977886500004388, 0.00974758499978634, 0.010645505999491434, 0.010036948000561097, 0.011089022000305704, 0.010468434000358684, 0.009621202998459921, 0.010368123001171625, 0.009560843000144814, 0.01032480200046848, 0.009355569000035757, 0.009949227000106475, 0.010504185000172583, 0.009506861000772915, 0.010086569000122836, 0.011642980000033276, 0.008981054999821936, 0.010035707999122678, 0.009105125998758012, 0.011191543000677484, 0.0103457619989058, 0.008856043001287617, 0.010719436999352183, 0.009265340000638389, 0.010239220999210374, 0.009949626999514294, 0.008725461000722134, 0.009362310000142315, 0.008942133999880753, 0.010235441000986611, 0.00917463800033147, 0.010426742999698035, 0.009771425000508316, 0.009886775998893427, 0.009630933000153163, 0.00997792799898889, 0.009916506000081426, 0.009967347999918275, 0.008842653000101564, 0.010903580001468072, 0.008944433999204193, 0.010119278998899972, 0.009634133999497863, 0.010005998999986332, 0.009508221000942285, 0.00949126100022113, 0.00993466699947021, 0.009433450999495108, 0.010527004000323359, 0.010040578999905847, 0.010075959999085171, 0.010271470999214216, 0.01006107800094469, 0.009780096001122729, 0.009509380999588757, 0.00954372200067155, 0.010697907000576379, 0.01007804899927578, 0.009817915999519755, 0.010542804000579054, 0.009483461999479914, 0.010196290999374469, 0.009739913999510463, 0.01037505299973418, 0.010261520999847562, 0.008948645001510158, 0.010540215000219177, 0.009400630000527599, 0.009696944000097574, 0.010373983001045417, 0.008872753000105149, 0.009967707001123927, 0.009099386999878334, 0.010399064000012004, 0.009341468999991775, 0.009639592999519664, 0.010610775998429745, 0.009275888000047416, 0.010415022999950452, 0.009081146999960765]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{withgrad_latency=}\")\n",
    "print(f\"{gradless_latency=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T12:00:33.909025Z",
     "iopub.status.busy": "2023-05-26T12:00:33.908471Z",
     "iopub.status.idle": "2023-05-26T12:00:39.609004Z",
     "shell.execute_reply": "2023-05-26T12:00:39.608226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================================================================================================================================================================================================\n",
      "This report only display top-level ops statistics\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                forward         3.00%      27.124ms        23.67%     214.027ms     305.753us       0.000us         0.00%     572.635ms     818.050us           0 b        -832 b       2.53 Gb    -791.35 Mb           700  \n",
      "                                ampere_sgemm_128x128_nt         0.00%       0.000us         0.00%       0.000us       0.000us     249.237ms        28.80%     249.237ms       2.492ms           0 b           0 b           0 b           0 b           100  \n",
      "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     241.722ms        27.93%     241.722ms       1.209ms           0 b           0 b           0 b           0 b           200  \n",
      "                                           aten::linear         0.23%       2.080ms         2.91%      26.297ms      43.828us       0.000us         0.00%     241.579ms     402.632us           0 b           0 b      62.81 Gb       3.01 Gb           600  \n",
      "void gemv2N_kernel<int, int, float, float, float, fl...         0.00%       0.000us         0.00%       0.000us       0.000us     154.150ms        17.81%     154.150ms     513.833us           0 b           0 b           0 b           0 b           300  \n",
      "void gemv2N_kernel<int, int, float, float, float, fl...         0.00%       0.000us         0.00%       0.000us       0.000us     100.102ms        11.57%     100.102ms     200.204us           0 b           0 b           0 b           0 b           500  \n",
      "std::enable_if<!(false), void>::type internal::gemvx...         0.00%       0.000us         0.00%       0.000us       0.000us      15.677ms         1.81%      15.677ms      78.385us           0 b           0 b           0 b           0 b           200  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us      12.796ms         1.48%      12.796ms      25.592us           0 b           0 b           0 b           0 b           500  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      12.287ms         1.42%      12.287ms       8.191us           0 b           0 b           0 b           0 b          1500  \n",
      "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us      12.231ms         1.41%      12.231ms      30.578us           0 b           0 b           0 b           0 b           400  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 904.150ms\n",
      "Self CUDA time total: 865.408ms\n",
      "\n",
      "===========================================================================================================================================================================================================================================================\n",
      "This report only display top-level ops statistics\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::linear         0.23%       2.080ms         2.91%      26.297ms      43.828us       0.000us         0.00%     241.579ms     402.632us           0 b           0 b      62.81 Gb       3.01 Gb           600  \n",
      "                                                forward         3.00%      27.124ms        23.67%     214.027ms     305.753us       0.000us         0.00%     572.635ms     818.050us           0 b        -832 b       2.53 Gb    -791.35 Mb           700  \n",
      "                                             aten::silu         0.57%       5.141ms         0.84%       7.555ms      15.110us       2.005ms         0.23%       2.005ms       4.010us           0 b           0 b     269.04 Mb     269.04 Mb           500  \n",
      "                                              aten::sin         0.28%       2.518ms         0.41%       3.748ms      12.493us     701.000us         0.08%     701.000us       2.337us           0 b           0 b     151.03 Mb     151.03 Mb           300  \n",
      "                                        aten::new_zeros         0.31%       2.807ms         2.21%      19.978ms      18.162us       0.000us         0.00%       1.493ms       1.357us           0 b           0 b     125.83 Mb     -18.93 Mb          1100  \n",
      "                                              aten::div         0.56%       5.088ms         0.85%       7.667ms      15.334us     914.000us         0.11%     914.000us       1.828us           0 b           0 b      30.42 Mb      30.42 Mb           500  \n",
      "                                            aten::index         0.32%       2.911ms         1.13%      10.243ms      51.215us     842.000us         0.10%     842.000us       4.210us           0 b           0 b      30.27 Mb      30.27 Mb           200  \n",
      "                                   _spherical_harmonics         0.16%       1.425ms         1.12%      10.082ms     100.820us       0.000us         0.00%       1.101ms      11.010us           0 b        -560 b      20.17 Mb     -20.92 Mb           100  \n",
      "                                              aten::pow         0.38%       3.438ms         0.53%       4.778ms      15.927us     879.000us         0.10%     879.000us       2.930us           0 b           0 b      15.23 Mb      15.23 Mb           300  \n",
      "                                       aten::reciprocal         0.24%       2.184ms         0.36%       3.263ms      10.877us     527.000us         0.06%     527.000us       1.757us           0 b           0 b      15.23 Mb      15.23 Mb           300  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 904.150ms\n",
      "Self CUDA time total: 865.408ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof_train.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10, top_level_events_only=True))\n",
    "print(prof_train.key_averages().table(sort_by=\"cuda_memory_usage\", row_limit=10, top_level_events_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T12:00:39.613700Z",
     "iopub.status.busy": "2023-05-26T12:00:39.613368Z",
     "iopub.status.idle": "2023-05-26T12:00:45.302425Z",
     "shell.execute_reply": "2023-05-26T12:00:45.301728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================================================================================================================================================================================================\n",
      "This report only display top-level ops statistics\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                forward         3.10%      27.375ms        20.50%     181.183ms     258.833us       0.000us         0.00%     568.922ms     812.746us           0 b        -888 b       1.56 Gb      -1.02 Gb           700  \n",
      "                                ampere_sgemm_128x128_nt         0.00%       0.000us         0.00%       0.000us       0.000us     248.013ms        28.73%     248.013ms       2.480ms           0 b           0 b           0 b           0 b           100  \n",
      "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     243.546ms        28.21%     243.546ms       1.218ms           0 b           0 b           0 b           0 b           200  \n",
      "                                           aten::linear         0.21%       1.845ms         2.69%      23.805ms      39.675us       0.000us         0.00%     241.884ms     403.140us           0 b           0 b      62.80 Gb       3.20 Gb           600  \n",
      "void gemv2N_kernel<int, int, float, float, float, fl...         0.00%       0.000us         0.00%       0.000us       0.000us     135.659ms        15.72%     135.659ms     452.197us           0 b           0 b           0 b           0 b           300  \n",
      "void gemv2N_kernel<int, int, float, float, float, fl...         0.00%       0.000us         0.00%       0.000us       0.000us     119.792ms        13.88%     119.792ms     239.584us           0 b           0 b           0 b           0 b           500  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us      12.776ms         1.48%      12.776ms      25.552us           0 b           0 b           0 b           0 b           500  \n",
      "std::enable_if<!(false), void>::type internal::gemvx...         0.00%       0.000us         0.00%       0.000us       0.000us      12.766ms         1.48%      12.766ms      63.830us           0 b           0 b           0 b           0 b           200  \n",
      "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us      12.255ms         1.42%      12.255ms      30.637us           0 b           0 b           0 b           0 b           400  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      12.253ms         1.42%      12.253ms       8.169us           0 b           0 b           0 b           0 b          1500  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 884.024ms\n",
      "Self CUDA time total: 863.205ms\n",
      "\n",
      "===========================================================================================================================================================================================================================================================\n",
      "This report only display top-level ops statistics\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::linear         0.21%       1.845ms         2.69%      23.805ms      39.675us       0.000us         0.00%     241.884ms     403.140us           0 b           0 b      62.80 Gb       3.20 Gb           600  \n",
      "                                                forward         3.10%      27.375ms        20.50%     181.183ms     258.833us       0.000us         0.00%     568.922ms     812.746us           0 b        -888 b       1.56 Gb      -1.02 Gb           700  \n",
      "                                             aten::silu         0.48%       4.246ms         0.75%       6.598ms      13.196us       1.783ms         0.21%       1.783ms       3.566us           0 b           0 b     269.04 Mb     269.04 Mb           500  \n",
      "                                              aten::sin         0.24%       2.090ms         0.36%       3.170ms      10.567us     732.000us         0.08%     732.000us       2.440us           0 b           0 b     151.03 Mb     151.03 Mb           300  \n",
      "                                        aten::new_zeros         0.32%       2.796ms         2.27%      20.027ms      18.206us       0.000us         0.00%       1.682ms       1.529us           0 b           0 b     125.83 Mb     -13.23 Mb          1100  \n",
      "                                              aten::div         0.54%       4.811ms         0.83%       7.378ms      14.756us     916.000us         0.11%     916.000us       1.832us           0 b           0 b      30.42 Mb      30.42 Mb           500  \n",
      "                                            aten::index         0.31%       2.702ms         0.55%       4.887ms      24.435us     865.000us         0.10%     865.000us       4.325us           0 b           0 b      30.27 Mb      30.27 Mb           200  \n",
      "                                   _spherical_harmonics         0.16%       1.428ms         1.16%      10.273ms     102.730us       0.000us         0.00%       1.092ms      10.920us           0 b        -552 b      20.17 Mb     -20.97 Mb           100  \n",
      "                                              aten::pow         0.36%       3.165ms         0.51%       4.502ms      15.007us     900.000us         0.10%     900.000us       3.000us           0 b           0 b      15.23 Mb      15.23 Mb           300  \n",
      "                                       aten::reciprocal         0.24%       2.082ms         0.35%       3.114ms      10.380us     525.000us         0.06%     525.000us       1.750us           0 b           0 b      15.23 Mb      15.23 Mb           300  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 884.024ms\n",
      "Self CUDA time total: 863.205ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof_test.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10, top_level_events_only=True))\n",
    "print(prof_test.key_averages().table(sort_by=\"cuda_memory_usage\", row_limit=10, top_level_events_only=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "It seems that the profiling does not take into account the fact that gradients have to be stored.  We think this, because the additional memory allocated to CUDA is more than 450 MB and more than 700 MB respectively when storing the gradients, but the profiler only gives 250 MB and 630 MB (per iteration) at most."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gvp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
