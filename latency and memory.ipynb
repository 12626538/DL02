{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latency and memory\n",
    "\n",
    "## How to run this file on the lisa cluster\n",
    "\n",
    "Start by pulling the lastest version of the repository, if necessary re-add the ssh-key to the agent.  ([See here](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent?platform=linux)), i.e.\n",
    "\n",
    "```sh\n",
    "eval \"$(ssh-agent -s)\"\n",
    "ssh-add ~/.ssh/id_ed25519\n",
    "```\n",
    "\n",
    "Then activate the correct modules (`2022` and `Anaconda3/2022.05`) and activate the `gvp` source.  Finally, actually run the notebook with \n",
    "\n",
    "```sh\n",
    "jupyter nbconvert \"latency and memory.ipynb\" --to notebook --execute --inplace --allow-errors\n",
    "```\n",
    "\n",
    "Make sure the environment contains the following packages: `ipywidgets`, `jupyter`, `notebook`, `torch`, `gvp`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "* Import things necessary for running GVP and SMLP, \n",
    "* Setup which task we analyse, \n",
    "* ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T12:51:13.827777Z",
     "iopub.status.busy": "2023-05-24T12:51:13.826999Z",
     "iopub.status.idle": "2023-05-24T12:51:13.837458Z",
     "shell.execute_reply": "2023-05-24T12:51:13.837023Z"
    }
   },
   "outputs": [],
   "source": [
    "# Supresses the following warning:\n",
    "#   UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class.\n",
    "#   This should only matter to you if you are using storages directly.\n",
    "#   To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T12:51:13.841820Z",
     "iopub.status.busy": "2023-05-24T12:51:13.841505Z",
     "iopub.status.idle": "2023-05-24T12:51:18.676123Z",
     "shell.execute_reply": "2023-05-24T12:51:18.675585Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from run_atom3d import get_datasets, get_model\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T12:51:18.680172Z",
     "iopub.status.busy": "2023-05-24T12:51:18.679709Z",
     "iopub.status.idle": "2023-05-24T12:51:18.686083Z",
     "shell.execute_reply": "2023-05-24T12:51:18.685683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Path to the best trained relevant model.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"../data/\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device != \"cuda\":\n",
    "    exit()\n",
    "\n",
    "TASK = \"LBA\"\n",
    "\"\"\"Task to test for model latency.\"\"\"\n",
    "LBA_SPLIT = 30\n",
    "# SPLIT = 60\n",
    "\n",
    "DATASET_SPLIT = \"train\"\n",
    "\"\"\"Dataset partition from which the sample is chosen.\"\"\"\n",
    "# Select from these values\n",
    "DATASET_SPLIT = [\"train\", \"val\", \"test\"].index(DATASET_SPLIT)\n",
    "SAMPLE_INDEX = 10\n",
    "\"\"\"Dataset index to use for testing the latency and memory.\"\"\"\n",
    "\n",
    "BEST_GVP_MODEL = \"./best_models/LBA_lba-split=30_47.pt\"\n",
    "\"\"\"Path to the best trained relevant model.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T12:51:18.729052Z",
     "iopub.status.busy": "2023-05-24T12:51:18.728239Z",
     "iopub.status.idle": "2023-05-24T12:51:20.696657Z",
     "shell.execute_reply": "2023-05-24T12:51:20.696175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[551, 3], edge_index=[2, 13194], atoms=[551], edge_s=[13194, 16], edge_v=[13194, 1, 3], label=6.85, lig_flag=[551], batch=[551])\n"
     ]
    }
   ],
   "source": [
    "datasets = get_datasets(TASK, DATA_DIR, LBA_SPLIT)\n",
    "\n",
    "gvp_model = get_model(TASK).to(device)\n",
    "# gvp_model = nn.DataParallel(gvp_model)  # Add parallel to fix OOM issues?\n",
    "gvp_model.load_state_dict(torch.load(BEST_GVP_MODEL), strict=False)\n",
    "\n",
    "dataset_sample = datasets[DATASET_SPLIT][SAMPLE_INDEX].to(device)\n",
    "# This is required for taking the scattermean of the graph\n",
    "dataset_sample.batch = torch.zeros_like(dataset_sample.atoms)\n",
    "\n",
    "print(dataset_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T12:51:20.699994Z",
     "iopub.status.busy": "2023-05-24T12:51:20.699147Z",
     "iopub.status.idle": "2023-05-24T12:51:22.194275Z",
     "shell.execute_reply": "2023-05-24T12:51:22.193660Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-05-24 14:51:20 28578:28578 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-05-24 14:51:22 28578:28578 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-05-24 14:51:22 28578:28578 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "# Burn once to prevent extra overhead for first CUDA profiling\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "             profile_memory=True) as prof:\n",
    "    gvp_model(dataset_sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T12:51:22.199778Z",
     "iopub.status.busy": "2023-05-24T12:51:22.199494Z",
     "iopub.status.idle": "2023-05-24T12:51:22.202902Z",
     "shell.execute_reply": "2023-05-24T12:51:22.202419Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_latency(model, dataset_sample):\n",
    "    start = time.perf_counter()\n",
    "    out = model(dataset_sample)\n",
    "    end = time.perf_counter()\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T12:51:22.207679Z",
     "iopub.status.busy": "2023-05-24T12:51:22.207421Z",
     "iopub.status.idle": "2023-05-24T12:51:22.674114Z",
     "shell.execute_reply": "2023-05-24T12:51:22.673636Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-05-24 14:51:22 28578:28578 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-05-24 14:51:22 28578:28578 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-05-24 14:51:22 28578:28578 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "STAGE:2023-05-24 14:51:22 28578:28578 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-05-24 14:51:22 28578:28578 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-05-24 14:51:22 28578:28578 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "gvp_model.train()\n",
    "# withgrad_latency = test_latency(gvp_model, dataset_sample)\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "             profile_memory=True) as prof_train:\n",
    "    out = gvp_model(dataset_sample)\n",
    "\n",
    "\n",
    "gvp_model.eval()\n",
    "with torch.no_grad():\n",
    "    # gradless_latency = test_latency(gvp_model, dataset_sample)\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "                profile_memory=True) as prof_test:\n",
    "        out = gvp_model(dataset_sample)\n",
    "\n",
    "# print(f\"{withgrad_latency=}\")\n",
    "# print(f\"{gradless_latency=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T12:51:22.679130Z",
     "iopub.status.busy": "2023-05-24T12:51:22.678525Z",
     "iopub.status.idle": "2023-05-24T12:51:22.969312Z",
     "shell.execute_reply": "2023-05-24T12:51:22.968896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================================================================================================================================================================================================\n",
      "This report only display top-level ops statistics\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::linear         2.51%     545.000us        32.43%       7.040ms      64.587us       0.000us         0.00%       6.420ms      58.899us           0 b           0 b     185.26 Mb     389.00 Kb           109  \n",
      "                                            aten::addmm         9.49%       2.061ms        13.91%       3.019ms      53.911us       2.962ms        29.29%       2.962ms      52.893us           0 b           0 b      95.57 Mb      41.57 Mb            56  \n",
      "                                   volta_sgemm_64x64_tt         0.00%       0.000us         0.00%       0.000us       0.000us       2.795ms        27.64%       2.795ms     254.091us           0 b           0 b           0 b           0 b            11  \n",
      "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us       2.070ms        20.47%       2.070ms     103.500us           0 b           0 b           0 b           0 b            20  \n",
      "                                  volta_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.293ms        12.79%       1.293ms      28.109us           0 b           0 b           0 b           0 b            46  \n",
      "                                              aten::cat         3.19%     693.000us         4.55%     988.000us      23.524us       1.268ms        12.54%       1.268ms      30.190us           0 b           0 b     253.17 Mb     253.17 Mb            42  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       1.122ms        11.09%       1.122ms      30.324us           0 b           0 b           0 b           0 b            37  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     376.000us         3.72%     376.000us      17.905us           0 b           0 b           0 b           0 b            21  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     327.000us         3.23%     327.000us       5.361us           0 b           0 b           0 b           0 b            61  \n",
      "                                              aten::sum         3.54%     768.000us         4.61%       1.001ms      25.667us     319.000us         3.15%     319.000us       8.179us           0 b           0 b      18.36 Mb      18.36 Mb            39  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 21.709ms\n",
      "Self CUDA time total: 10.113ms\n",
      "\n",
      "===========================================================================================================================================================================================================================================================\n",
      "This report only display top-level ops statistics\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                              aten::cat         3.19%     693.000us         4.55%     988.000us      23.524us       1.268ms        12.54%       1.268ms      30.190us           0 b           0 b     253.17 Mb     253.17 Mb            42  \n",
      "                                            aten::addmm         9.49%       2.061ms        13.91%       3.019ms      53.911us       2.962ms        29.29%       2.962ms      52.893us           0 b           0 b      95.57 Mb      41.57 Mb            56  \n",
      "                                              aten::mul         3.61%     784.000us         4.96%       1.076ms      23.391us     245.000us         2.42%     245.000us       5.326us           0 b           0 b      39.42 Mb      39.42 Mb            46  \n",
      "                                             aten::sqrt         2.25%     489.000us         3.24%     703.000us      18.026us      98.000us         0.97%      98.000us       2.513us           0 b           0 b      18.62 Mb      18.62 Mb            39  \n",
      "                                              aten::sum         3.54%     768.000us         4.61%       1.001ms      25.667us     319.000us         3.15%     319.000us       8.179us           0 b           0 b      18.36 Mb      18.36 Mb            39  \n",
      "                                            aten::clamp         3.03%     657.000us         4.16%     903.000us      20.523us     108.000us         1.07%     108.000us       2.455us           0 b           0 b      17.93 Mb      17.93 Mb            44  \n",
      "                                          aten::sigmoid         2.04%     442.000us         2.87%     622.000us      23.923us      67.000us         0.66%      67.000us       2.577us           0 b           0 b      12.64 Mb      12.64 Mb            26  \n",
      "                                              aten::add         2.18%     473.000us         3.20%     694.000us      17.350us      89.000us         0.88%      89.000us       2.225us           0 b           0 b       6.23 Mb       6.23 Mb            40  \n",
      "                                              aten::div         1.87%     405.000us         2.57%     557.000us      20.630us      76.000us         0.75%      76.000us       2.815us           0 b           0 b       3.83 Mb       3.83 Mb            27  \n",
      "                                       aten::layer_norm         0.32%      70.000us         2.61%     567.000us      43.615us       0.000us         0.00%      82.000us       6.308us           0 b           0 b       3.30 Mb     929.00 Kb            13  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 21.709ms\n",
      "Self CUDA time total: 10.113ms\n",
      "\n",
      "\n",
      "===========================================================================================================================================================================================================================================================\n",
      "This report only display top-level ops statistics\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::linear         3.22%     529.000us        38.98%       6.409ms      58.798us       0.000us         0.00%       6.333ms      58.101us           0 b           0 b     186.05 Mb       3.79 Mb           109  \n",
      "                                   volta_sgemm_64x64_tt         0.00%       0.000us         0.00%       0.000us       0.000us       2.792ms        28.10%       2.792ms     253.818us           0 b           0 b           0 b           0 b            11  \n",
      "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us       2.073ms        20.86%       2.073ms     103.650us           0 b           0 b           0 b           0 b            20  \n",
      "                                  volta_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.289ms        12.97%       1.289ms      28.022us           0 b           0 b           0 b           0 b            46  \n",
      "                                              aten::cat         3.08%     507.000us         4.60%     756.000us      18.000us       1.261ms        12.69%       1.261ms      30.024us           0 b           0 b     252.66 Mb     252.66 Mb            42  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       1.117ms        11.24%       1.117ms      30.189us           0 b           0 b           0 b           0 b            37  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     376.000us         3.78%     376.000us      17.905us           0 b           0 b           0 b           0 b            21  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     327.000us         3.29%     327.000us       5.361us           0 b           0 b           0 b           0 b            61  \n",
      "                                              aten::sum         3.68%     605.000us         5.01%     823.000us      21.103us     320.000us         3.22%     320.000us       8.205us           0 b           0 b      17.63 Mb      17.63 Mb            39  \n",
      "                                             aten::relu         0.38%      62.000us         1.81%     298.000us      18.625us       0.000us         0.00%     217.000us      13.562us           0 b           0 b      54.75 Mb           0 b            16  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 16.442ms\n",
      "Self CUDA time total: 9.936ms\n",
      "\n",
      "===========================================================================================================================================================================================================================================================\n",
      "This report only display top-level ops statistics\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                              aten::cat         3.08%     507.000us         4.60%     756.000us      18.000us       1.261ms        12.69%       1.261ms      30.024us           0 b           0 b     252.66 Mb     252.66 Mb            42  \n",
      "                                              aten::mul         2.20%     362.000us         3.07%     504.000us      19.385us     195.000us         1.96%     195.000us       7.500us           0 b           0 b      37.91 Mb      37.91 Mb            26  \n",
      "                                            aten::clamp         2.93%     482.000us         4.35%     716.000us      16.273us     108.000us         1.09%     108.000us       2.455us           0 b           0 b      17.64 Mb      17.64 Mb            44  \n",
      "                                              aten::sum         3.68%     605.000us         5.01%     823.000us      21.103us     320.000us         3.22%     320.000us       8.205us           0 b           0 b      17.63 Mb      17.63 Mb            39  \n",
      "                                             aten::sqrt         2.09%     343.000us         3.27%     538.000us      13.795us      98.000us         0.99%      98.000us       2.513us           0 b           0 b      17.29 Mb      17.29 Mb            39  \n",
      "                                          aten::sigmoid         1.86%     306.000us         2.77%     456.000us      17.538us      70.000us         0.70%      70.000us       2.692us           0 b           0 b      12.64 Mb      12.64 Mb            26  \n",
      "                                              aten::add         2.38%     392.000us         3.79%     623.000us      15.575us     101.000us         1.02%     101.000us       2.525us           0 b           0 b       6.23 Mb       6.23 Mb            40  \n",
      "                                           aten::linear         3.22%     529.000us        38.98%       6.409ms      58.798us       0.000us         0.00%       6.333ms      58.101us           0 b           0 b     186.05 Mb       3.79 Mb           109  \n",
      "                                              aten::div         1.17%     193.000us         1.70%     279.000us      16.412us      56.000us         0.56%      56.000us       3.294us           0 b           0 b       2.82 Mb       2.82 Mb            17  \n",
      "                                             aten::mean         1.05%     173.000us         1.47%     241.000us      20.083us      57.000us         0.57%      57.000us       4.750us           0 b           0 b      79.50 Kb      79.50 Kb            12  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 16.442ms\n",
      "Self CUDA time total: 9.936ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof_train.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10, top_level_events_only=True))\n",
    "print(prof_train.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=10, top_level_events_only=True))\n",
    "print()\n",
    "print(prof_test.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10, top_level_events_only=True))\n",
    "print(prof_test.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=10, top_level_events_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T12:51:22.974505Z",
     "iopub.status.busy": "2023-05-24T12:51:22.973917Z",
     "iopub.status.idle": "2023-05-24T12:51:23.663059Z",
     "shell.execute_reply": "2023-05-24T12:51:23.662585Z"
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Here comes the latency of the steerable implementation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHere comes the latency of the steerable implementation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Here comes the latency of the steerable implementation."
     ]
    }
   ],
   "source": [
    "raise NotImplementedError(\"Here comes the latency of the steerable implementation.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T12:51:23.667949Z",
     "iopub.status.busy": "2023-05-24T12:51:23.667629Z",
     "iopub.status.idle": "2023-05-24T12:51:23.670355Z",
     "shell.execute_reply": "2023-05-24T12:51:23.669967Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_memory(model, dataset_sample):\n",
    "    start = torch.cuda.memory_allocated()\n",
    "    out = model(dataset_sample)\n",
    "    end = torch.cuda.memory_allocated()\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T12:51:23.673359Z",
     "iopub.status.busy": "2023-05-24T12:51:23.673084Z",
     "iopub.status.idle": "2023-05-24T12:51:23.713728Z",
     "shell.execute_reply": "2023-05-24T12:51:23.713286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "withgrad_latency=487282176\n",
      "gradless_latency=512\n"
     ]
    }
   ],
   "source": [
    "gvp_model.train()\n",
    "withgrad_latency = test_memory(gvp_model, dataset_sample)\n",
    "\n",
    "gvp_model.eval()\n",
    "with torch.no_grad():\n",
    "    gradless_latency = test_memory(gvp_model, dataset_sample)\n",
    "\n",
    "print(f\"{withgrad_latency=}\")\n",
    "print(f\"{gradless_latency=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T12:51:23.717687Z",
     "iopub.status.busy": "2023-05-24T12:51:23.717404Z",
     "iopub.status.idle": "2023-05-24T12:51:23.732317Z",
     "shell.execute_reply": "2023-05-24T12:51:23.731896Z"
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Here comes the latency of the steerable implementation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHere comes the latency of the steerable implementation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Here comes the latency of the steerable implementation."
     ]
    }
   ],
   "source": [
    "raise NotImplementedError(\"Here comes the latency of the steerable implementation.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gvp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
