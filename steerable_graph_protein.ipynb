{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steerable Graph Convolutions for Learning Protein Structures\n",
    "<!-- An analysis of the paper and its key components. Think about it as nicely formatted review as you would see on OpenReview.net -->\n",
    "by *Synthesized Solututions*\n",
    "\n",
    "Machine learning is increasingly being applied to the analysis of molecules for tasks such as protein design, model quality assessment, and ablation studies. These techniques can help us better understand the structure and function of proteins, which is useful for many medical application, such as drug discovery. Convolutional Neural Networks (CNNs) and Graph Neural Networks (GNNs) are two types of machine learning models that are  particularly well-suited for analyzing molecular data. CNNs can operate directly on the geometry of a structure and GNNs are expressive in terms of relational reasoning.\n",
    "\n",
    "- something about them being translation equivariant/invariant\n",
    "- problem of not being rotation equivariant \n",
    "\n",
    "<!-- State something about it still being hard to make these models rotation equivariant; and write what equivariant is? -->\n",
    "\n",
    "- Shift invariance is achieved in CNNs -> convolutional layers are shift equivariant (since convolutions are shift equivariant) and pooling layers are shift invariant (even if image is shifted -a little bit- the max e.g. will remain the same)\n",
    "- CNNs are not rotation equivariant; if an image is shifted, it is not detected by the same filter as before, so CNN needs to learn every filter for every possible rotation (very inconvenient): \"Although, a deep CNN can be made rotationally equivalent by making the network explicitly learn the different feature maps at rotated versions of the input image. But in this approach, CNN is compelled to learn the rotated versions of the same image which increases the risk of overfitting and introduces a redundant degree of freedom.\"\n",
    "- GNNs are great and all, but not rotation equivariant; doesn't see the molecule that is rotated one way as the same molecule rotated another way\n",
    "\n",
    "Formally we can define equivariance as follows:\n",
    "$$f(g\\cdot x) = g\\cdot f(x)$$\n",
    "\n",
    "\n",
    "\n",
    "In order to keep more geometric information, Jing, Eismann, Suriana, Townshend, and Dror (2020) propose a modification to the standard GNN by changing the multilayer perceptrons (MLPs) with geometric vector perceptrons (GVPs). The approach described in the paper, GVPs, are used to learn the relationship between protein sequences and their structures. GVPs are a type of layer that operates on geometric objects, such as vectors and matrices, rather than on scalar values like most neural networks. This makes GVPs well-suited to tasks that involve analyzing spatial relationships, such as predicting protein structures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib  \n",
    "gvp = importlib.import_module(\"gvp-pytorch.gvp\")\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\"SMP\", \"PSR\", \"RSR\", \"MSP\", \"SMP\", \"LBA\", \"LEP\"] #,'PPI', 'RES']\n",
    "\n",
    "args = {\"task\": tasks[0], # see options above\n",
    "        \"num-workers\": 4,\n",
    "        \"smp-idx\": None, # range 0-19\n",
    "        \"batch\": 8,\n",
    "        \"lba-split\": 30, # 30 or 60\n",
    "        \"train-time\": 120, # in minutes\n",
    "        \"val-time\": 20, # in minutes\n",
    "        \"epochs\": 50,\n",
    "        \"test\": None, # path to evaluate a trained model\n",
    "        \"lr\": 1e-4,\n",
    "        \"load\": None, # path to initialize first 2 GNN layers with pretrained weights\n",
    "        \"save\": \"models\", # directory to save models to\n",
    "        \"data\": \"data\", # directory to data\n",
    "        \"monitor\": True, # trigger tensorboard monitoring\n",
    "        \"no-pbar\": True, # when set, do not show TWDM bars\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.9619, -0.4841, -0.1284, -1.1194,  3.3360, -0.9701,  0.0931,  2.5875,\n",
      "          0.7545, -1.4744],\n",
      "        [ 1.5812, -2.0930,  1.6547,  0.0272,  0.8697,  1.1716,  0.4379, -1.3952,\n",
      "          1.4812,  0.2163],\n",
      "        [ 1.9377, -0.8061, -0.2328, -0.1506, -0.5729, -1.2459,  1.4393,  1.2837,\n",
      "          1.0559, -0.3273]]), tensor([[[-1.0871,  0.2218,  2.4097],\n",
      "         [-1.4756, -0.6310, -0.0874],\n",
      "         [ 1.5917, -0.1781, -0.7701],\n",
      "         [ 1.1409,  2.2131, -0.9159],\n",
      "         [ 0.7890,  0.3483, -0.3917],\n",
      "         [-0.0260,  0.0851, -1.5376],\n",
      "         [-0.9060,  0.8046, -1.3302],\n",
      "         [ 0.6292, -0.4953, -1.5158],\n",
      "         [-0.0615,  0.5774,  0.7823],\n",
      "         [-0.2549, -0.2908, -0.2219]],\n",
      "\n",
      "        [[ 0.1714,  0.0084, -1.3378],\n",
      "         [-0.5415,  1.4138, -1.6238],\n",
      "         [ 0.7055, -0.1119, -2.1222],\n",
      "         [-0.8087, -0.5466, -0.8699],\n",
      "         [ 1.9468,  0.5484,  0.4135],\n",
      "         [ 0.8651, -0.3576, -1.5791],\n",
      "         [ 0.0067, -2.1135, -0.1313],\n",
      "         [-0.3478, -0.7424, -0.5761],\n",
      "         [ 1.0100, -0.0944,  0.2323],\n",
      "         [-0.5707,  0.6014,  0.2882]],\n",
      "\n",
      "        [[-1.2803, -0.2854, -0.6490],\n",
      "         [-0.9016, -1.3578, -0.5361],\n",
      "         [-0.2558, -0.4159, -0.3428],\n",
      "         [ 0.3161, -0.1449, -1.1851],\n",
      "         [ 1.8362, -2.5591, -1.5308],\n",
      "         [-0.1380, -0.6689,  0.9843],\n",
      "         [ 0.6427, -0.9144, -0.7316],\n",
      "         [-0.3825, -0.8395,  0.4892],\n",
      "         [ 0.2273, -0.9846, -0.7436],\n",
      "         [ 0.1675, -0.9264,  0.6922]]]))\n"
     ]
    }
   ],
   "source": [
    "### OUR CODE HERE\n",
    "# from run_atom3d import *\n",
    "\n",
    "\n",
    "\n",
    "# datasets = get_datasets(args.task, args.data, args.lba_split)\n",
    "# dataloader = partial(torch_geometric.loader.DataLoader,\n",
    "#                 num_workers=args.num_workers, batch_size=args.batch)\n",
    "# if args.task not in ['PPI', 'RES']:\n",
    "#     dataloader = partial(dataloader, shuffle=True)\n",
    "\n",
    "# trainset, valset, testset = map(dataloader, datasets)\n",
    "# model = get_model(args.task).to(device)\n",
    "# model = nn.DataParallel(model)\n",
    "\n",
    "# if args.test:\n",
    "#     test(model, testset)\n",
    "# some test stuff\n",
    "scalars_in, vectors_in = 10, 10\n",
    "scalars_out, vectors_out = 10, 10\n",
    "\n",
    "in_dims = scalars_in, vectors_in\n",
    "out_dims = scalars_out, vectors_out\n",
    "gvp_ = gvp.GVP(in_dims, out_dims)\n",
    "\n",
    "gvp_ = gvp.GVP(in_dims, out_dims,\n",
    "            activations=(F.relu, None), vector_gate=True)\n",
    "\n",
    "dropout = gvp.Dropout(drop_rate=0.1)\n",
    "layernorm = gvp.LayerNorm(out_dims)\n",
    "\n",
    "x = gvp.randn(n=5, dims=in_dims)\n",
    "# x = (s, V) with s.shape = [5, scalars_in] and V.shape = [5, vectors_in, 3]\n",
    "\n",
    "out = gvp_(x)\n",
    "out = dropout(out)\n",
    "out = layernorm(out)\n",
    "\n",
    "y = gvp.randn(n=5, dims=in_dims)\n",
    "z = gvp.tuple_sum(x, y)\n",
    "z = gvp.tuple_cat(x, y, dim=-1) # concat along channel axis\n",
    "z = gvp.tuple_cat(x, y, dim=-2) # concat along node / batch axis\n",
    "\n",
    "node_mask = torch.rand(5) < 0.5\n",
    "z = gvp.tuple_index(x, node_mask) # select half the nodes / batch at random\n",
    "\n",
    "print(z)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exposition of its weaknesses/strengths/potential which triggered your group to come with a response.\n",
    "\n",
    "- Current model is not very expressive; it's not steerable; can only handle type-1\n",
    "  - GVPs would kind of be part of the Invariant Message Passing NNs?\n",
    "  - So I consider it as a “incomplete” steerable mlp\n",
    "  - My point is that steerable MLP can enable the information exchange between all possible pairs of vectors (type 0, 1, …, n), but GVP can only exchange the information from scalar vector to type-1 vector by using gating and from type-1 vector to scalar using norm.\n",
    "- only invariant to rotation, due to taking norm (scalar value) (i think)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe your novel contribution.\n",
    "- changing the GVP layers to steerable graph convolutions layers\n",
    "- perhaps change the k in knn for these graph convolution (message passing layers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hidden stuff\n",
    "<!-- ipv xyz  componenten steerable componenten om het equivariant te maken\n",
    "- invariant op dit moment meer omdat oprolling van allerlei \\/ moleculen (die wel allemaal andere kant opstaan) worden nu zelfde behandelt als allerlei \\/ moleculen op een rechte lijn\n",
    "- door equivariant te maken (met steerable) hopen wij dat deze wel verschillend worden behandeld\n",
    "\n",
    "- scalar features (zijn sowieso al rotation invariant, ze hebben geen hoek) en vector features  (rotation invariant atm) waarvan we ook de norm nemen -> scalar dus rotation invariant -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support your contribution with actual code and experiments (hence the colab format!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-eae693bd15f6f7c0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-eae693bd15f6f7c0\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### OUR CODE HERE\n",
    "\n",
    "# testje om te zien of we de tfevent files direct kunnen visualiseren in de notebook\n",
    "# ik moet nu deze cel 2x runnen voor tensorboard daadwerkelijk zichtbaar word\n",
    "%load_ext tensorboard \n",
    "%tensorboard --logdir tfevent-files/\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the notebook with a description of the each students' contribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
